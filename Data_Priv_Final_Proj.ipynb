{
 "cells": [
  {
   "cell_type": "code",
   "id": "cd4685c3-c916-46de-a72d-f2be9b6d8cb5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T19:54:13.211596Z",
     "start_time": "2025-12-04T19:54:13.116436Z"
    }
   },
   "source": [
    "# Load the data and libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def laplace_mech(v, sensitivity, epsilon):\n",
    "    return v + np.random.laplace(loc=0, scale=sensitivity / epsilon)\n",
    "\n",
    "def gaussian_mech(v, sensitivity, epsilon, delta):\n",
    "    return v + np.random.normal(loc=0, scale=sensitivity * np.sqrt(2*np.log(1.25/delta)) / epsilon)\n",
    "\n",
    "def gaussian_mech_vec(vec, sensitivity, epsilon, delta):\n",
    "    return [v + np.random.normal(loc=0, scale=sensitivity * np.sqrt(2*np.log(1.25/delta)) / epsilon)\n",
    "            for v in vec]"
   ],
   "outputs": [],
   "execution_count": 44
  },
  {
   "cell_type": "code",
   "id": "4f42beae-fb25-4cbb-8813-fd5a0f0132c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T19:54:15.594182Z",
     "start_time": "2025-12-04T19:54:14.761061Z"
    }
   },
   "source": [
    "# Load the data and libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "bear = pd.read_csv('https://raw.githubusercontent.com/jbennett979/Data_Privacy_FP/refs/heads/main/north_america_bear_killings.csv')"
   ],
   "outputs": [],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T20:04:33.131619Z",
     "start_time": "2025-12-04T20:04:33.105314Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load data files\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "import io\n",
    "\n",
    "#url_x_pre = pd.read_csv('https://raw.githubusercontent.com/jbennett979/Data_Privacy_FP/refs/heads/main/north_america_bear_killings_processed_x.csv')\n",
    "#url_y_pre = pd.read_csv('https://raw.githubusercontent.com/jbennett979/Data_Privacy_FP/refs/heads/main/north_america_bear_killings_processed_y.csv')\n",
    "\n",
    "#url_x_pre = url_x_pre.dropna()\n",
    "#url_y_pre = url_y_pre.dropna()\n",
    "\n",
    "#X = url_x_pre.to_numpy()\n",
    "#y = url_y_pre.to_numpy()\n",
    "\n",
    "x_pre = bear[[' age', 'Month', 'Year', 'Grizzly', 'Hikers', 'Only one killed']]\n",
    "y_pre = bear['Hunter']\n",
    "\n",
    "x_pre[['Grizzly', 'Hikers', 'Only one killed']] = x_pre[['Grizzly', 'Hikers', 'Only one killed']].replace(0, -1)\n",
    "print(x_pre)\n",
    "\n",
    "X = x_pre.to_numpy()\n",
    "y = y_pre.to_numpy()\n"
   ],
   "id": "7b6e235f50ec7b94",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      age  Month  Year  Grizzly  Hikers  Only one killed\n",
      "0      27      6  2017       -1      -1                1\n",
      "1      16      6  2017       -1      -1                1\n",
      "2      27      5  2015       -1      -1                1\n",
      "3      22      9  2014       -1       1                1\n",
      "4      36      5  2014       -1      -1                1\n",
      "..    ...    ...   ...      ...     ...              ...\n",
      "159     1     10  1908       -1      -1                1\n",
      "160    18     11  1906       -1      -1                1\n",
      "161     3      5  1901       -1      -1               -1\n",
      "162     5      5  1901       -1      -1               -1\n",
      "163     7      5  1901       -1      -1               -1\n",
      "\n",
      "[164 rows x 6 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jess\\AppData\\Local\\Temp\\ipykernel_12204\\397768559.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x_pre[['Grizzly', 'Hikers', 'Only one killed']] = x_pre[['Grizzly', 'Hikers', 'Only one killed']].replace(0, -1)\n"
     ]
    }
   ],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T20:05:53.838560Z",
     "start_time": "2025-12-04T20:05:53.831426Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Split data into training and test sets\n",
    "training_size = int(X.shape[0] * 0.8)\n",
    "\n",
    "X_train = X[:training_size]\n",
    "X_test = X[training_size:]\n",
    "\n",
    "y_train = y[:training_size]\n",
    "y_test = y[training_size:]\n",
    "\n",
    "print('Train and test set sizes:', len(y_train), len(y_test))\n"
   ],
   "id": "782f861641e77529",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train and test set sizes: 131 33\n"
     ]
    }
   ],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T20:05:55.205087Z",
     "start_time": "2025-12-04T20:05:55.174320Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# This is the gradient of the logistic loss\n",
    "# The gradient is a vector that indicates the rate of change of the loss in each direction\n",
    "def gradient(theta, xi, yi):\n",
    "    exponent = yi * (xi.dot(theta))\n",
    "    return - (yi*xi) / (1+np.exp(exponent))\n",
    "\n",
    "def predict(xi, theta, bias=0):\n",
    "    label = np.sign(xi @ theta + bias)\n",
    "    return label\n",
    "\n",
    "def accuracy(theta):\n",
    "    return np.sum(predict(X_test, theta) == y_test)/X_test.shape[0]\n",
    "\n",
    "def L2_clip(v, b):\n",
    "    norm = np.linalg.norm(v, ord=2)\n",
    "    \n",
    "    if norm > b:\n",
    "        return b * (v / norm)\n",
    "    else:\n",
    "        return v\n",
    "\n",
    "def gradient_sum(theta, X, y, b):\n",
    "    gradients = [L2_clip(gradient(theta, x_i, y_i), b) for x_i, y_i in zip(X,y)]\n",
    "        \n",
    "    # sum query\n",
    "    # L2 sensitivity is b (by clipping performed above)\n",
    "    return np.sum(gradients, axis=0)\n",
    "   \n",
    "\n",
    "def noisy_gradient_descent(iterations, epsilon, delta):\n",
    "    theta = np.zeros(X_train.shape[1])\n",
    "    b = 3\n",
    "\n",
    "    noisy_count = laplace_mech(X_train.shape[0], 1, epsilon)\n",
    "\n",
    "    for i in range(iterations):\n",
    "        clipped_gradient_sum = gradient_sum(theta, X_train, y_train, b)\n",
    "        noisy_gradient_sum = np.array(gaussian_mech_vec(clipped_gradient_sum, b, epsilon, delta))\n",
    "        noisy_avg_gradient = noisy_gradient_sum / noisy_count\n",
    "        theta = theta - noisy_avg_gradient\n",
    "\n",
    "    return theta\n",
    "\n",
    "theta = noisy_gradient_descent(10, 10.0, 1e-5)\n",
    "print('Final accuracy:', accuracy(theta))"
   ],
   "id": "9693cc81da3f653f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final accuracy: 0.09090909090909091\n"
     ]
    }
   ],
   "execution_count": 56
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T20:05:56.434914Z",
     "start_time": "2025-12-04T20:05:56.412518Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def gaussian_mech_RDP_vec(vec, sensitivity, alpha, epsilon):\n",
    "    sigma = np.sqrt((sensitivity**2 * alpha) / (2 * epsilon))\n",
    "    return [v + np.random.normal(loc=0, scale=sigma) for v in vec]\n",
    "\n",
    "def noisy_gradient_descent_RDP(iterations, alpha, epsilon_bar):\n",
    "    epsilon_i = epsilon_bar/(iterations+1)\n",
    "    theta = np.zeros(X_train.shape[1])\n",
    "    noisy_count = gaussian_mech_RDP_vec(pd.Series([len(X_train)]), sensitivity=1, alpha=alpha, epsilon=epsilon_i)\n",
    "    for i in range(iterations):\n",
    "        grads = [gradient(theta, x_i, y_i) for x_i, y_i in zip(X_train, y_train)]\n",
    "        b = 3 # clipping parameter (for the L2)\n",
    "        clipped_grads = [L2_clip(g, b) for g in grads]\n",
    "        sum_grad = np.sum(clipped_grads, axis=0)\n",
    "        noisy_sum = gaussian_mech_RDP_vec(sum_grad, sensitivity=b, alpha=alpha, epsilon=epsilon_i)\n",
    "        noisy_grad = np.array(noisy_sum) / noisy_count\n",
    "        theta = theta - noisy_grad\n",
    "    return theta\n",
    "\n",
    "theta = noisy_gradient_descent_RDP(10, 20, 0.1)\n",
    "print('Final accuracy:', accuracy(theta))"
   ],
   "id": "98e86cd3a0cbadd3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final accuracy: 0.09090909090909091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jess\\AppData\\Local\\Temp\\ipykernel_12204\\3922538417.py:5: RuntimeWarning: overflow encountered in exp\n",
      "  return - (yi*xi) / (1+np.exp(exponent))\n"
     ]
    }
   ],
   "execution_count": 57
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "862bc60acf487c46"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
